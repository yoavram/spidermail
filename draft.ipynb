{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests as req\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_depth = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "email_pattern = re.compile(r\"[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+(?:[A-Z]{2}|com|org|net|edu|gov|mil|biz|info|mobi|name|aero|asia|jobs|museum|mx|com\\.mx|xxx|tv|tk)\\b\")\n",
      "url_pattern = re.compile(r'href=[\\'\"]?([^\\'\" >]+)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_urls(filename=\"urls.txt\"):\n",
      "    urls = {}\n",
      "    with open(filename) as fin:\n",
      "        for line in fin:\n",
      "            urls[line.strip()] = 0\n",
      "    return urls\n",
      "urls = load_urls()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_emails(url):\n",
      "    if not url.startswith('http://'):\n",
      "        url = base_url + url\n",
      "    r = req.get(url)\n",
      "    if not r.ok:\n",
      "        print \"Failed getting emails from\", url\n",
      "        return\n",
      "    emails = email_pattern.findall(r.content)\n",
      "    emails = list(set(emails))\n",
      "    return emails\n",
      "        \n",
      "get_emails(r'/faculty/directory/10010/Alford')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "['johnson@law.harvard.edu', 'alford@law.harvard.edu']"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_base_url(url):\n",
      "    if url.startswith('http://'):\n",
      "        i = url[7:].index('/')\n",
      "        base_url = url[:i+7]\n",
      "    else:\n",
      "        i = url.index('/')\n",
      "        base_url = url[:i]\n",
      "    return base_url\n",
      "base_url = get_base_url(urls.keys()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_urls(url, depth):\n",
      "    base_url = get_base_url(url)\n",
      "    r = req.get(url)\n",
      "    if not r.ok:\n",
      "        print \"Failed getting links from\", url\n",
      "        return\n",
      "    links = url_pattern.findall(r.content)\n",
      "    print \"Got %d links from %s\" % (len(links), url)\n",
      "    for i,link in enumerate(links):\n",
      "        if link.startswith('/'):\n",
      "            link = base_url + link\n",
      "        elif not links.startswith(base_url):\n",
      "            continue\n",
      "        else:\n",
      "            urls[link] = depth + 1\n",
      "    return links"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_depth = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crawl(urls):\n",
      "    emails = []\n",
      "    links = {}\n",
      "    for url,depth in urls.items():\n",
      "        emails.extend( get_emails(url) )\n",
      "        if depth < max_depth:\n",
      "            links.update( get_links(url,depth) )\n",
      "    if links:\n",
      "        emails.extend(crawl(links))\n",
      "    return emails\n",
      "emails = crawl(urls)\n",
      "print emails"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got 141 links from http://www.law.harvard.edu/faculty/\n",
        "Failed getting emails from"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "'NoneType' object is not iterable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-88-356d7dab1013>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0memails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0memails\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0memails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0memails\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-88-356d7dab1013>\u001b[0m in \u001b[0;36mcrawl\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mlinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mget_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0memails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0memails\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0memails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-88-356d7dab1013>\u001b[0m in \u001b[0;36mcrawl\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0memails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mget_emails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mlinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mget_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.law.harvard.edu/a\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_emails(emails, filename=\"emails.txt\"):\n",
      "    with open(filename, 'w') as fout:\n",
      "        for em in emails:\n",
      "            fout.write(em)\n",
      "            fout.write('\\n')\n",
      "    print \"%d emails written to %s\" % (len(emails), filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_emails(filename=\"emails.txt\"):\n",
      "    emails = []\n",
      "    with open(\"mails_%s.txt\" % url.replace(':','_').replace('/','_')) as fin:\n",
      "        emails.append( fin.read() )\n",
      "    print \"%d emails read from %s\" % (len(emails), filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_emails(urls.keys()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 86,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}